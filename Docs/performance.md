# Performance Analysis Methodology and Results

## Methodology

Для аналізу продуктивності API-сервісу було використано вбудовані інструменти Visual Studio:

- **CPU Profiler** — для аналізу навантаження на процесор.
- **Memory Profiler** — для дослідження використання пам’яті.
- **Application Insights** — для збору метрик, моніторингу запитів, CPU, пам’яті, продуктивності бази даних, та ін.

Було також виконано моделювання великого обсягу запитів до API — прогнозування з 2023 по 2025 рік — для створення навантаження та виявлення «вузьких місць».

## Memory Profiling

- Найбільш пам’яттєємними об'єктами виявилися:
  - **Python CLR**
- Після багаторазових запитів пік використання пам’яті стабілізувався на ~1.1 ГБ.
- Було зроблено кілька знімків пам’яті для порівняння змін — з’ясовано, що найбільше зростає Python CLR, який варто оптимізувати.

## CPU Profiling

- CPU Profiler активувався через breakpoint у кінці запиту.
- Профайлер дозволив відстежити завантаження Python-моделі, кешування, авторизацію в БД.
- Під час першого запиту:
  - Завантажуються бібліотеки Python.
  - Ініціалізується авторизація, яка займала до **20%** часу.

## Database Query Analysis

- Загалом було 3 запити:
  - Найважчий запит — ініціалізація доступів користувача (разовий, не потребує оптимізації).
  - Основний запит до бази — отримання за PK, оптимізація можлива заміною `FirstOrDefault` на `Find`.

## Caching Strategy

- Проведено експеримент: без кешування модель завжди завантажується зі сховища.
- Результати:
  - Без кешу середній час відповіді зріс до **3 секунд**.
  - Кожен запит звертається до зовнішнього сховища.
  - З кешем — перший запит довгий, наступні — значно швидші.

Пропозиція: зберігати модель у фоні (background), не чекаючи завершення асинхронної операції. Це пришвидшує відповіді, але потребує контролю помилок.